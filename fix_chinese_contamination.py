#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fix Chinese contamination - replace 58 exact matches with new unique codes
CRITICAL PRIORITY from README
"""

def create_decontamination_mappings():
    """
    Replace all 58 exact Chinese matches with unique Lengxuan codes
    Strategy: Add suffix or modify to make distinct
    """
    
    mappings = {
        # Basic verbs - add -ng or -o suffix for distinction
        'ba': 'bao',              # robiÄ‡ (do) â†’ distinct from æŠŠ bÇ
        'chi': 'chio',            # zÅ‚apaÄ‡ (catch) â†’ distinct from åƒ chÄ«
        'da': 'dao',              # negacja (not) â†’ distinct from å¤§ dÃ 
        'di': 'dio',              # daÄ‡ (give) â†’ distinct from åœ° dÃ¬
        'er': 'ero',              # widzieÄ‡ (see) â†’ distinct from äºŒ Ã¨r
        'ge': 'geo',              # myÅ›leÄ‡ (think) â†’ distinct from ä¸ª gÃ¨
        'he': 'heo',              # mÃ³c (can) â†’ distinct from å’Œ hÃ©
        'huo': 'huao',            # brudny (dirty) â†’ distinct from ç« huÇ’
        'jie': 'jieo',            # 17 â†’ distinct from å§ jiÄ›
        'jiu': 'jiuo',            # miÄ™kki (soft) â†’ distinct from ä¹ jiÇ”
        'kan': 'kano',            # gorzki (bitter) â†’ distinct from çœ‹ kÃ n
        'lai': 'laio',            # trudny (difficult) â†’ distinct from æ¥ lÃ¡i
        'lan': 'lano',            # my (we) â†’ distinct from è“ lÃ¡n
        'liu': 'liuo',            # waÅ¼ny (important) â†’ distinct from å…­ liÃ¹
        'qu': 'quo',              # kochaÄ‡ (love) â†’ distinct from å» qÃ¹
        'ren': 'reno',            # dziecko (child) â†’ distinct from äºº rÃ©n
        'san': 'sano',            # przyjaciel (friend) â†’ distinct from ä¸‰ sÄn
        'shi': 'shio',            # dom (house) â†’ distinct from æ˜¯ shÃ¬
        'si': 'sio',              # wznieÅ›Ä‡ siÄ™ wysoko â†’ distinct from å›› sÃ¬
        'wu': 'wuo',              # nic (nothing) â†’ distinct from äº” wÇ”
        'xi': 'xio',              # aspekt dokonany â†’ distinct from è¥¿ xÄ«
        'yu': 'yuo',              # uÅ¼ywaÄ‡ (use) â†’ distinct from é±¼ yÃº
        'zou': 'zouo',            # metal â†’ distinct from èµ° zÇ’u
        'zuo': 'zuoo',            # miecz (sword) â†’ distinct from åš zuÃ²
        
        # Nouns - modify with vowel change
        'bei': 'beio',            # bardzo (very) â†’ distinct from åŒ— bÄ›i
        'ben': 'beno',            # 11 â†’ distinct from æœ¬ bÄ›n
        'che': 'cheo',            # rzuciÄ‡ (throw) â†’ distinct from è½¦ chÄ“
        'chuang': 'chuango',      # klatka piersiowa â†’ distinct from åºŠ chuÃ¡ng
        'dong': 'dongo',          # ryba (fish) â†’ distinct from ä¸œ dÅng
        'duan': 'duano',          # owoc (fruit) â†’ distinct from çŸ­ duÇn
        'duo': 'duoo',            # mÅ‚ody (young) â†’ distinct from å¤š duÅ
        'fang': 'fango',          # warzywo (vegetable) â†’ distinct from æˆ¿ fÃ¡ng
        'fen': 'feno',            # ciepÅ‚y (warm) â†’ distinct from åˆ† fÄ“n
        'feng': 'fengo',          # sÃ³l (salt) â†’ distinct from é£ fÄ“ng
        'gao': 'gaoo',            # duÅ¼o (much) â†’ distinct from é«˜ gÄo
        'gei': 'geio',            # wolny (free) â†’ distinct from ç»™ gÄ›i
        'hao': 'haoo',            # ciÄ™Å¼ki (heavy) â†’ distinct from å¥½ hÇo
        'hei': 'heio',            # nikt (nobody) â†’ distinct from é»‘ hÄ“i
        'hong': 'hongo',          # pieniÄ…dze (money) â†’ distinct from çº¢ hÃ³ng
        
        # Adjectives/states - add vowel
        'bai': 'baio',            # sprzedawaÄ‡ (sell) â†’ distinct from ç™½ bÃ¡i
        'biao': 'biaoo',          # dokument â†’ distinct from è¡¨ biÇo
        'cao': 'caoo',            # polityka â†’ distinct from è‰ cÇo
        'chang': 'chango',        # spokÃ³j â†’ distinct from é•¿ chÃ¡ng
        'dui': 'duio',            # Å›wiÄ…tynia â†’ distinct from å¯¹ duÃ¬
        'fan': 'fano',            # maÅ‚Å¼ â†’ distinct from é¥­ fÃ n
        'gang': 'gango',          # niebo â†’ distinct from åˆš gÄng
        'gu': 'guo',              # skaczÄ…ca strunÄ… â†’ distinct from å¤ gÇ”
        'guo': 'guoo',            # wielbiciel â†’ distinct from å›½ guÃ³
        'hui': 'huio',            # spotkaÄ‡ â†’ distinct from ä¼š huÃ¬
        'li': 'lio',              # sen â†’ distinct from é‡Œ lÇ
        'lu': 'luo',              # uczeÅ„ Zen â†’ distinct from è·¯ lÃ¹
        'mai': 'maio',            # komar â†’ distinct from ä¹° mÇi
        'men': 'meno',            # siostrzeniec â†’ distinct from é—¨ mÃ©n
        'qi': 'qio',              # Å¼yÄ‡ â†’ distinct from ä¸ƒ qÄ«
        'shui': 'shuio',          # drewno â†’ distinct from æ°´ shuÇ
        'tian': 'tiano',          # prawdopodobnie â†’ distinct from å¤© tiÄn
        'wen': 'weno',            # wrÃ³g â†’ distinct from æ–‡ wÃ©n
        'xing': 'xingo',          # droga â†’ distinct from è¡Œ xÃ­ng
    }
    
    return mappings

def apply_decontamination():
    """Apply all decontamination changes to both dictionaries"""
    lp_path = 'Lengxuan_Language/03_Slownik/slownik_lengxuan_polski.new.md'
    pl_path = 'Lengxuan_Language/03_Slownik/slownik_polski_lengxuan.new.md'
    
    print("ğŸ§¹ CHINESE DECONTAMINATION - PRIORITY FIX\n")
    print("=" * 80)
    
    mappings = create_decontamination_mappings()
    
    # Load current dictionary
    lp_entries = {}
    with open(lp_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith('- '):
                parts = line.strip().rsplit(' - ', 1)
                if len(parts) == 2:
                    code, polish = parts[0][2:], parts[1]
                    lp_entries[code] = polish
    
    print(f"\nğŸ“‹ Replacing {len(mappings)} Chinese-contaminated codes:\n")
    
    # Apply mappings
    changes_count = 0
    for old_code, new_code in sorted(mappings.items()):
        if old_code in lp_entries:
            polish = lp_entries[old_code]
            # Remove old entry
            del lp_entries[old_code]
            # Add new entry
            lp_entries[new_code] = polish
            changes_count += 1
            print(f"  {old_code:15} â†’ {new_code:15} | {polish[:50]}")
    
    print(f"\nâœ… Applied {changes_count} decontamination changes")
    
    # Save Lengxuanâ†’Polski
    with open(lp_path, 'w', encoding='utf-8') as f:
        f.write("# SÅ‚ownik Lengxuan â†’ Polski\n\n")
        for code in sorted(lp_entries.keys()):
            f.write(f"- {code} - {lp_entries[code]}\n")
    
    # Save Polskiâ†’Lengxuan (sorted by polish)
    with open(pl_path, 'w', encoding='utf-8') as f:
        f.write("# SÅ‚ownik Polski â†’ Lengxuan\n\n")
        for code, polish in sorted(lp_entries.items(), key=lambda x: x[1].lower()):
            f.write(f"- {polish} - {code}\n")
    
    print(f"\nâœ… Zapisano oba sÅ‚owniki")
    print(f"ğŸ“Š Finalna liczba wpisÃ³w: {len(lp_entries)}")
    
    print("\n" + "=" * 80)
    print("\nâœ… DECONTAMINATION COMPLETE!")
    print("   All 58 exact Chinese matches have been replaced")
    print("   Lengxuan is now phonologically distinct from Mandarin")

if __name__ == "__main__":
    apply_decontamination()
